%% Theorie.tex
%%
%\usepackage[ngerman]{babel}
%% ==============
\chapter{Algorithmen zur multivariaten Analyse}
\label{ch:algorithmen}
%% ==============

{\bibliographystyle{babalpha-fl}}	% german style

Multivariate Datenanalyse spielt in der experimentellen Hochenergiephysik eine entscheidente Rolle um die gr\"o\ss en gemessenen Datenmengen (big data) untersuchen und auswerten zu k\"onnen. Im folgenden Kapitel \ref{ch:algorithmen} werden zun\"achst einige Grundlagen der multivariaten Datenanalyse genannt, um sp\"ater genauer auf verschiedene Algorithmen und ihre Implementationen anhand kleinerer Beispiele einzugehen.

%% ===========================
\section{Grundlagen zur multivariaten Datenanalyse}
\label{ch:Theorie:sec:Algorithmen}
%% ===========================

Datenanalyse bezeichnet statistische Verfahren, mit deren Hilfe aus numerischen Daten Informationen gewonnen werden sollen.
Bei multivariaten Analysemethoden werden mehrere Eingabegr\"o\ss en zugleich statistisch untersucht, dadurch ist eine Berechnung sehr aufw\"andig und somit manuell nicht zu bewerkstelligen. Mithilfe der zunehmenden Rechenleistung aktueller Computer ist dies jedoch m\"oglich und wird in vielen Bereichen immer wichtiger, beispielsweise im Finanzwesen, bei Studien zum Konsumverhalten, oder der Sprach-, Schrift- und Bilderkennung.
Die dazu verwendeten Algorithmen bezeichnet man auch als maschinelles Lernen (machine learning), da mit ihrer hilfe versucht wird, aus den Daten zu lernen und Vorhersagen zu treffen. Man unterscheidet zwischen Regression (regression), bei der eine kontinuirliche Ausgangsgr\"o\ss e gesucht wird und Klassifizierung (classification), bei der eine diskrete Antwort gesucht wird.\cite{SWB-455193959} Im Fall der \ttH-Analyse werden Regre\ss ionsmodelle verwendet um physikalische Gr\"o\ss en wie beispielsweise die Higgsbosonmasse zu rekonstruieren. Bei der Klassifizierung wird dagegen versucht, ein Ereignis einer Klasse zuzuordnen, also entweder Signal (englisch signal) oder Untergrund (englisch background). Im Folgenden werden ausschlie\ss lich Klassifizierungsprobleme behandelt.

Es existieren verschiedene Ans\"atze zur Klassifizierung. Einer dieser Ans\"atze ist das \"uberwachte Lernen (supervised learning). Beispiele sind die St\"utzvektormethode, wobei jedoch die englische Bezeichnung support vector machine (SVM) gebr\"auchlich ist, Random Forest (RF), was Zuf\"alliger Wald bedeutet und mehrere zuf\"allig erstellte Entscheidungsb\"aume (Abschnitt \ref{ch:Algorithmen:subsec:Entscheidungsbaum} bezeichnet, oder Neuronale Netze. Ein weiteres Beispiel sind verst\"arkte Entscheidungsb\"aume (Boosted Decision Trees (BDTs)). Da hiervon verschiedene Implementationen im Kapitel \ref{ch:vergleich} untersucht und getestet werden sollen, werden sie im folgenden Abschnitt \ref{ch:Algorithmen:sec:BDT} genauer beschrieben.

%% ===========================
\section{Boosted Decision Trees (BDTs)}
\label{ch:Algorithmen:sec:BDT}
%% ===========================

Boosted Decision Trees sind eine h\"aufig genutze Methode der multivariaten Datenanalyse. Im folgenden werden sie anhand eines einfachen Beispiels erkl\"art. Bei diesem handelt es sich um zwei zweidimensionale Gau\ss kurven die sich \"uberlappen. Eine stellt das Signal dar, die andere dient als Hintergrund. In Abbildung \ref{fig:2dgauss_scatter} ist ein Streudiagramm (scatterplot) dieser Verteilung abgebildet. X und Y dienen hier als trennende Variablen.

%% ===========================
\subsection{Entscheidungsb\"aume}
\label{ch:Algorithmen:subsec:Entscheidungsbaum}
%% ===========================

Entscheidungsb\"aume unterteilen den Bereich des zu klassifizierenden Objektes anhand gerader Schnitte auf dessen Eigenschaften (Variablen) in mehrere Sequenzen. Wieviele dieser Sequenzen ab dem Wurzelknoten erstellt werden, wird durch die Tiefe (depth) des Baumes angegeben. In Abbildung \ref{fig:DecicionTree} (links) ist ein Beispiel eines Baumes mit der Tiefe zwei zu sehen. An jedem Knoten werden die Objekte aufgrund ihrer Eigenschaften und Kriterien in Signal und Untergrund unterteilt. Im Wurzelknoten ist der erste diskriminierende Schnitt angegeben. Alle Objekte mit einem Y-Wert gr\"o\ss er als 0.33 werden als eher Hintergrundartig eingestuft. In der n\"achsten Stufe des Baumes werden f\"ur jede der beiden zuvor getrennten Mengen Schnitte auf den X-Wert angewendet. In Abbildung \ref{fig:DecicionTree} (rechts) ist die Ausgabe (output) dieses Baumes abgebildet, das heist jedem Punkt wird entsprechend seiner X- und Y-Koordinaten ein Wert zugeordnet, der angibt, ob der Punkt eher als Signal oder als Untergrund klassifieziert wurde. man sieht deutlich die verschiedenen Schnitte.\\
\begin{figure}[hhh]
 \begin{center}
   \includegraphics[width=\textwidth]{graphics/tree.pdf}
   \parbox[b]{12cm}{
     \caption[Entscheidungsbaumes der Tiefe 2]
             {\label{fig:DecicionTree} \it schematische Abbildung eines Entscheidungsbaumes der Tiefe 2. X und Y sind die Variablen anhand denen durch cuts (Zahlen nach den Variablen) zwischen Untergrund und Signal unterschieden werden soll.\\Erstellt mit TMVA}
   }
 \end{center}
\end{figure}
Man unterscheidet zwischen zwei Arten, bin\"aren B\"aumen mit diskreten R\"uckgabewerten zur Unterscheidung mehrerer Klassen (classification trees), zum Beispiel Signal und Untergrund, sowie denjenigen mit kontinuierlicher Antwort (regression trees). \cite{SWB-455193959}

%BDTs vereinen durch Boosting und Bagging (aus dem Englischen von bootstrap aggregation abgeleitet) mehrere Entscheidungsb\"aume zu einem starken Kla\ss ifikator.

%% ===========================
\subsection{Verst\"arken von Entscheidungsb\"aumen (Boosting)}
\label{ch:Algorithmen:subsec:Boosting}
%% ===========================

%% ===========================
\section{Verwendete Algorithmen zur multivariaten Analyse}
\label{ch:Algorithmen:subsec:Implementationen}
%% ===========================

%% ===========================
\subsection{Toolkit for Multivariate Analysis in ROOT (TMVA)}
\label{ch:Algorithmen:subsec:TMVA}
%% ===========================

%% ===========================
\subsection{scikit-learn -- machine learning in python}
\label{ch:Algorithmen:subsec:sklearn}
%% ===========================

%% ===========================
\subsection{Extreme Gradient Boosting (XGBoost)}
\label{ch:Algorithmen:subsec:XGB}
%% ===========================
