%% Theorie.tex
%%
%\usepackage[ngerman]{babel}
%% ==============
\chapter{Vergleich der multivariaten Algorithmen}
\label{ch:vergleich}
%% ==============

%{\bibliographystyle{babalpha-fl}}	% german style
{\bibliographystyle{babunsrt-fl}}

In diesem Kapitel wird zun\"achst erl\"autert, anhand welcher Kriterien die verwendeten Algorithmen miteinander verglichen werden k\"onnen. Anschlie\ss end werden verschiedene Datens\"atze mithilfe der Algorithmen untersucht und die Ergebnisse verglichen.

%% ===========================
\section{Vergleichbarkeit der Algorithmen}
\label{ch:Vergleich:sec:Vergleichbarkeit}
%% ===========================

Bevor die verschiedenen Implementationen der Algorithmen verglichen werden k\"onnen, m\"ussen zun\"achst einige Vergleichskriterien festgelegt werden. Au\ss erdem muss \"uberpr\"uft werden, inwieweit sich die Parameter der Algorithmen unterscheiden.\\
In Tabelle \ref{tab:parameter} sind die Einstellungsm\"oglichkeiten der drei Algorithmen dargestellt.

\begin{table}[hhh]\parbox{12cm}{
  \caption[Algorithmenparameter]{\it Tabelle mit einstellbaren Parametern der verschiedenen Algorithmen}% {\rm \cite{Agashe:2014kda}}
  }\label{tab:parameter}
  \begin{center}
  \begin{tabular}{p{3.75cm}p{2.75cm}p{2.25cm}p{4.5cm}}
  \hline
  {\bf TMVA} & {\bf scikit-learn} & {\bf XGBoost} & {\bf Funktion} \\
  \hline \hline
     NTrees	& n\_estimators & n\_estimators & Anzahl der Entscheidungsb\"aume \\
     Shrinkage	& learning\_rate & learning\_rate & Lernrate des Gradient Boosting \\
     MaxDepth & max\_depth & max\_depth & Tiefe der Entscheidungsb\"aume\\
     nCuts & -- & -- & Anzahl an getesteten Schnitten\\ 
  	 MinNodeSize & min\_samples\_leaf & reg\_lambda & Minimalanzahl Ereignisse pro Knoten\\ 
  	 BaggedSampleFraction & subsample & subsample & Gr\"o\ss e der Teilmengen des Trainingsdatensatzes f\"ur Bagging\\                     
  \hline
  \end{tabular}
  \end{center}
\end{table}

Die Lernrate, die Anzahl an Entscheidungsb\"aumen sowie die Tiefe der B\"aume haben bei allen drei Algorithmen die gleiche Funktion. Die Anzahl der zu testenden Schnitte ist nur in TMVA regelbar. Dies k\"onnte daran liegen, dass in TMVA viele Berechnungen mithilfe von den in ROOT implementierten Histogrammen durchgef\"uhrt werden, w\"ahrend Scikit-Learn Arrays verwendet, die keine Schnitte ben\"otigen sondern eine kontinuierliche \"Uberpr\"ufung der Ausgabe erm\"oglichen. 

Die minimale Anzahl an Ereignissen pro Knoten legt fest, ab wann ein Entscheidungsbaum beschnitten werden soll. In TMVA wird dies \"uber einen Prozentsatz des Trainingsdatensatzes festgelegt, w\"ahrend in Scikit-Learn ein Absolutwert genutzt wird. In XGBoost wird dies durch einen Vergleich der Ereignisgewichte erreicht.

Um nur die Gr\"o\ss e der zuf\"alligen Teilmenge einzustellen, die jeder Entscheidungsbaum durch Bagging zum Training nutzt, dient die \glqq BaggedSampleFraction\grqq~sowie das \glqq subsample\grqq. Beide sind Parameter im Bereich zwischen 0 und 1 und werden mit der Gesamtanzahl der Trainingsereignisse multipliziert, um die Anzahl der Ereignisse pro Baum zu erhalten.

Au\ss erdem m\"ussen zun\"achst Kriterien gefunden werden, anhand deren die BDT-Ausgaben miteinander verglichen werden k\"onnen. In dieser Arbeit werden ROC-Kurve (Abschnitt \ref{ch:Vergleich:subsec:ROC}) sowie das Integral der ROC-Kurven zum Vergleich der Klassifikationsqualit\"at und der Kolmogorov-Smirnoff-Test (Abschnitt \ref{ch:Vergleich:subsec:KSTest}) zur Untersuchung ob ein Generalisierungsfehler vorliegt verwendet.

%% ===========================
\subsection{ROC-Kurve}
\label{ch:Vergleich:subsec:ROC}
%% ===========================

Receiver-Operating-Characteristic-Kurven (ROC-Kurven) sind Kennlinien, die sich als n\"utzliche Technik zur Visualisierung der G\"ute eines Klassifikators herausgestellt haben.

In einem ROC-Graphen wird die Sensitivit\"at (true-positive-rate) \"uber der Spezifit\"at (1 - false-positive-rate) aufgetragen. Dabei ist die Sensitivit\"at definiert als
\beq
tpr = \frac{\text{korrekt~klassifizierte~Signalereignisse}}{\text{Gesamtanzahl~Signalereignisse}}
\label{eq:TPR}
\eeq
und die Spezitivit\"at als
\beq
1-fpr = 1-\frac{\text{falsch~klassifizierte~Untergrundereignisse}}{\text{Gesamtanzahl~Untergrundereignisse}}.
\label{eq:1-FPR}
\eeq
%
Manchmal wird auch die true-positive-rate \"uber der false-positive-rate aufgetragen. Dadurch erh\"alt man eine ansteigende ROC-Kurve. An den Eigenschaften der ROC-Kurve \"andert das allerdings nichts.

F\"ur jeden diskrete Unterscheidung wird ein Punkt der ROC-Kurve erzeugt. Dieser Punkt besteht aus einem Wertepaar der Form $((1-fpr),tpr)$. F\"ur einen Entscheidungsbaum der Tiefe zwei erh\"alt man also zwei Punkte. Au\ss erdem enth\"alt jede ROC-Kurve die Punkte $(0,1)$, was bedeutet, dass kein Ereignis als Signal eingestuft wird und $(1,0)$, an dem alle Ereignisse als Signal eingestuft werden. Diese Punkte werden durch Geraden verbunden, um eine gemittelte Kurve zu erhalten.\\
Die schlechtest m\"ogliche Klassifikation w\"urde eine Gerade zwischen diesen beiden Punkten ergeben und entspricht einer zuf\"alligen Einteilung in Signal und Untergrund. Eine perfekte Klassifikation w\"urde den Punkt $(1,1)$ ergeben. Somit w\"urde man eine Fl\"ache unter der ROC-Kurve von eins erhalten. Diese Fl\"ache wird ebenfalls als Vergleichskriterium f\"ur Klassifikatoren benutzt. Man nennt sie auch ROC-Integral oder ROC-AUC (f\"ur area under curve) \cite{ROC_Graphs}.

%% ===========================
\subsection{Kolmogorow-Smirnow-Test}
\label{ch:Vergleich:subsec:KSTest}
%% ===========================

Der Kolmogorow-Smirnow-Test ist ein statistischer Test mit dem gepr\"uft wird, wie gut zwei verschiedene Verteilungsfunnktionen \"ubereinstimmen.\\
Um eine Klassifikation eines BDTs auf Overtraining zu testen wird jeweils eine Verteilungsfunktion der BDT-Ausgabe auf den Trainingsdatensatz und auf den Testdatensatz erstellt. Dies geschieht indem man die BDT-Ausgaben $x_i$ der Gr\"o\ss e nach sortiert. Die Verteilungsfunktionen sind dann
\beq
F_{train}(x) = \frac{\text{Anzahl~der~x$_i$-Werte} \leq x}{n}
\label{eq:CDF_train}
\eeq
und f\"ur den Testdatensatz entsprechend.\\
Gesucht wird die gr\"o\ss te Differenz zwischen diesen beiden Verteilungen
\beq
t = \sqrt{n}\cdot\max\left|F_{train}(x)-F_{test}(x)\right|.
\label{eq:KSTest}
\eeq
D.h. je kleiner dieser Wert ist, desto besser stimmen die Verteilungsfunktionen \"uberein \cite{Blobel}. Wenn dieser Wert f\"ur Test- und Trainingsdaten gro\ss  wird, so liegt ein Generalisierungsfehler vor.

Oft wird auch die Wahrscheinlichkeit berechnet, einen Wert kleiner t zu erhalten. In diesem Fall sind die Verteilungen bei kleinen Wahrscheinlichkeiten nicht kompatibel. Diese Wahrscheinlichkeit wird zum Beispiel von der in ROOT implementierten Funktion des KS-Tests als R\"uckgabewert genutzt \cite{ROOT:TH1F}.

\begin{table}[hhh]\parbox{12cm}{
  \caption[TMVA 6j4t Ergebnisse]{\it Tabelle mit TMVA BDT-Ausgaben}% {\rm \cite{Agashe:2014kda}}
  }\label{tab:tmva}
  \begin{center}
  \begin{tabular}{llll}
  \hline
  Trainingszeit in $s$ & ROC-Integral & KS-Test Signal & KS-Test Untergrund\\
  \hline
  \hline
179.72 & 0.7292 & 0.20 & 0.34\\ 
176.39 & 0.7315 & 0.28 & 0.97\\ 
177.61 & 0.7329 & 0.21 & 0.99\\ 
177.02 & 0.7337 & 0.22 & 0.99\\ 
174.75 & 0.7342 & 0.11 & 1.0\\ 
201.52 & 0.7294 & 0.23 & 0.86\\ 
204.64 & 0.7319 & 0.23 & 0.99\\ 
195.36 & 0.7332 & 0.19 & 0.99\\ 
193.92 & 0.7339 & 0.17 & 0.99\\ 
200.38 & 0.7343 & 0.17 & 0.98\\ 
211.11 & 0.7297 & 0.26 & 0.78\\ 
218.64 & 0.7321 & 0.26 & 0.99\\ 
219.69 & 0.7335 & 0.20 & 0.98\\ 
226.88 & 0.7341 & 0.16 & 0.99\\ 
215.05 & 0.7344 & 0.23 & 0.98\\ 
246.53 & 0.7300 & 0.23 & 0.72\\ 
243.78 & 0.7325 & 0.23 & 0.99\\
253.18 & 0.7337 & 0.17 & 0.98\\ 
244.71 & 0.7342 & 0.18 & 0.99\\ 
248.4  & 0.7345 & 0.29 & 0.94\\ 
286.38 & 0.7302 & 0.26 & 0.90\\ 
281.77 & 0.7327 & 0.21 & 0.98\\ 
286.48 & 0.7339 & 0.15 & 1.0\\ 
285.86 & 0.7344 & 0.20 & 1.0\\ 
289.66 & 0.7345 & 0.20 & 0.97\\ 
  \hline
  \end{tabular}
  \end{center}
\end{table}

%% ===========================
\section{Verwendete Datens\"atze}
\label{ch:Vergleich:sec:Daten}
%% ===========================

Um die 

%% ===========================
\section{Anwendung und Vergleich der Algorithmen zur ttH Analyse}
\label{ch:Vergleich:sec:ttH}
%% ===========================
