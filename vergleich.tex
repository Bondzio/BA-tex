%% Theorie.tex
%%
%\usepackage[ngerman]{babel}
%% ==============
\chapter{Vergleich der multivariaten Algorithmen}
\label{ch:vergleich}
%% ==============

%{\bibliographystyle{babalpha-fl}}	% german style
{\bibliographystyle{babunsrt-fl}}

In diesem Kapitel wird zun\"achst erl\"autert, anhand welcher Kriterien die verwendeten Algorithmen miteinander verglichen werden k\"onnen. Anschlie\ss end werden die Algorithmen auf zwei verschiedene S\"atze von CMS-Simulationsdaten angewandt und die Ergebnisse verglichen.

%% ===========================
\section{Vergleichbarkeit der Algorithmen}
\label{ch:Vergleich:sec:Vergleichbarkeit}
%% ===========================

Bevor die verschiedenen Implementationen der Algorithmen verglichen werden k\"onnen, m\"ussen zun\"achst einige Vergleichskriterien festgelegt werden. Au\ss erdem muss \"uberpr\"uft werden, inwieweit sich die Parameter der Algorithmen unterscheiden.\\
In Tabelle \ref{tab:parameter} sind die Einstellungsm\"oglichkeiten der drei Algorithmen dargestellt.

\begin{table}[tbp]\parbox{12cm}{
  \caption[Algorithmenparameter]{Tabelle mit einstellbaren Parametern der verschiedenen Algorithmen}% {\rm \cite{Agashe:2014kda}}
  }\label{tab:parameter}
  \begin{center}
  \begin{tabular}{p{3.75cm}p{2.75cm}p{2.25cm}p{4.5cm}}
  \hline
  {\bf TMVA} & {\bf scikit-learn} & {\bf XGBoost} & {\bf Funktion} \\
  \hline \hline
     NTrees	& n\_estimators & n\_estimators & Anzahl der Entscheidungsb\"aume \\
     Shrinkage	& learning\_rate & learning\_rate & Lernrate des Gradient Boosting \\
     MaxDepth & max\_depth & max\_depth & Tiefe der Entscheidungsb\"aume\\
     nCuts & -- & -- & Anzahl an getesteten Schnitten\\ 
  	 MinNodeSize & min\_samples\_leaf & reg\_lambda & Minimalanzahl Ereignisse pro Knoten\\ 
  	 BaggedSampleFraction & subsample & subsample & Gr\"o\ss e der Teilmengen des Trainingsdatensatzes f\"ur Bagging\\                     
  \hline
  \end{tabular}
  \end{center}
\end{table}

Die Lernrate, die Anzahl an Entscheidungsb\"aumen sowie die Tiefe der B\"aume haben bei allen drei Algorithmen die gleiche Funktion. Die Anzahl der zu testenden Schnitte ist nur in TMVA regelbar. Dies k\"onnte daran liegen, dass in TMVA viele Berechnungen mithilfe von der ROOT implementierten Histogramme durchgef\"uhrt werden, w\"ahrend Scikit-Learn Arrays verwendet, die keine Schnitte ben\"otigen sondern eine kontinuierliche \"Uberpr\"ufung der Ausgabe erm\"oglichen. 

Die minimale Anzahl an Ereignissen pro Knoten legt fest, ab wann ein Entscheidungsbaum beschnitten werden soll. In TMVA wird dies \"uber einen Prozentsatz des Trainingsdatensatzes festgelegt, w\"ahrend in Scikit-Learn ein Absolutwert genutzt wird. In XGBoost wird dies durch einen Vergleich der Ereignisgewichte erreicht.

Um nur die Gr\"o\ss e der zuf\"alligen Teilmenge einzustellen, die jeder Entscheidungsbaum durch Bagging zum Training nutzt, dient die \glqq BaggedSampleFraction\grqq~in TMVA sowie das \glqq subsample\grqq in Scikit-Learn und XGBoost. Beide sind Parameter im Bereich zwischen 0 und 1 und werden mit der Gesamtanzahl der Trainingsereignisse multipliziert, um die Anzahl der Ereignisse pro Baum zu erhalten.

Au\ss erdem m\"ussen zun\"achst Kriterien gefunden werden, anhand derer die BDT-Ausgaben miteinander verglichen werden k\"onnen. In dieser Arbeit werden ROC-Kurve (Abschnitt~\ref{ch:Vergleich:subsec:ROC}) sowie das Integral der ROC-Kurven zum Vergleich der Klassifikationsqualit\"at und der Kolmogorov-Smirnov-Test (Abschnitt \ref{ch:Vergleich:subsec:KSTest}) zur Untersuchung, ob ein Generalisierungsfehler vorliegt, verwendet.

%% ===========================
\subsection{ROC-Kurve}
\label{ch:Vergleich:subsec:ROC}
%% ===========================

Receiver-Operating-Characteristic-Kurven (ROC-Kurven) sind Kennlinien, die sich als n\"utzliche Technik zur Visualisierung der G\"ute eines Klassifikators herausgestellt haben.

In einem ROC-Graphen wird die Sensitivit\"at (Richtig-Positiv-Rate) \"uber der Spezifit\"at (1 - Falsch-Positiv-Rate) aufgetragen. Dabei ist die Sensitivit\"at definiert als
\beq
tpr = \frac{\text{korrekt~klassifizierte~Signalereignisse}}{\text{Gesamtanzahl~Signalereignisse}}
\label{eq:TPR}
\eeq
und die Spezifit\"at als
\beq
1-fpr = 1-\frac{\text{falsch~klassifizierte~Untergrundereignisse}}{\text{Gesamtanzahl~Untergrundereignisse}}.
\label{eq:1-FPR}
\eeq
%
Manchmal wird auch die Richtig-Positiv-Rate \"uber der Falsch-Positiv-Rate aufgetragen. Dadurch erh\"alt man eine ansteigende ROC-Kurve. An den Eigenschaften der ROC-Kurve \"andert das allerdings nichts.

F\"ur jede diskrete Unterscheidung wird ein Punkt der ROC-Kurve erzeugt. Dieser Punkt besteht aus einem Wertepaar der Form $((1-fpr),tpr)$. F\"ur einen Entscheidungsbaum der Tiefe zwei erh\"alt man also drei Punkte. Au\ss erdem enth\"alt jede ROC-Kurve die Punkte $(0,1)$, was bedeutet, dass kein Ereignis als Signal eingestuft wird und $(1,0)$, an dem alle Ereignisse als Signal eingestuft werden. Diese Punkte werden durch Geraden verbunden, um eine gemittelte Kurve zu erhalten.\\
Die schlechtest m\"ogliche Klassifikation w\"urde eine Gerade zwischen diesen beiden Punkten ergeben und entspricht einer zuf\"alligen Einteilung in Signal und Untergrund. Eine perfekte Klassifikation w\"urde den Punkt $(1,1)$ ergeben. Somit w\"urde man eine Fl\"ache unter der ROC-Kurve von eins erhalten. Diese Fl\"ache wird ebenfalls als Vergleichskriterium f\"ur Klassifikatoren benutzt. Man nennt sie auch ROC-Integral oder ROC-AUC (f\"ur area under curve) \cite{ROC_Graphs}.

\begin{figure}[tbp]
\centering     %%% not \center
\subfigure[ROC-Kurve eines Baumes der Tiefe zwei]{\label{fig:ROC_1}\includegraphics[width=0.49\textwidth]{graphics/ROC_1.pdf}}
\subfigure[ROC-Kurve eines BDT mit 1000 B\"aumen der Tiefe zwei]{\label{fig:ROC_1000}\includegraphics[width=0.49\textwidth]{graphics/ROC_1000.pdf}}
\caption{Links sieht man die ROC-Kurve einer Klassifikation mit einem einzelnen Baum der Tiefe zwei. Rechts ist eine ROC-Kurve eines BDTs mit 1000 B\"aumen der Tiefe zwei abgebildet.}
\end{figure}

In Abbildung \ref{fig:ROC_1} ist eine ROC-Kurve der Klassifikation eines einzelnen Entscheidungsbaumes zu sehen. In Abbildung \ref{fig:ROC_1000} ist eine ROC-Kurve der Klassifikation eines BDTs mit 1000 B\"aumen der Tiefe zwei zu sehen. Die Kurve wird deutlich runder, da mehr Unterscheidungen getroffen werden k\"onnen und somit mehr Wertepaare f\"ur die ROC-Kurve erzeugt werden. Au\ss erdem wird die Fl\"ache unter der Kurve gr\"o\ss er, was auf die bessere Klassifikation hinweist.
Erzeugt wurden beide ROC-Kurven mit einer Pythonfunktion anhand einer Klassifikation des Beispiels aus Abschnitt \ref{ch:Algorithmen:sec:BDT} mit Scikit-Learn.

%% ===========================
\subsection{Kolmogorov-Smirnov-Test}
\label{ch:Vergleich:subsec:KSTest}
%% ===========================

Der Kolmogorov-Smirnov-Test ist ein statistischer Test, mit dem gepr\"uft wird, wie gut zwei verschiedene Verteilungsfunktionen \"ubereinstimmen.\\
Um eine Klassifikation eines BDTs auf \"Uberanpassung zu testen wird jeweils eine Verteilungsfunktion der BDT-Ausgabe auf den Trainingsdatensatz und auf einen unabh\"angigen Testdatensatz erstellt. Dies geschieht indem man die BDT-Ausgaben $x_i$ der Ereignisse $i$ der Gr\"o\ss e nach sortiert. Die Verteilungsfunktionen sind dann
\beq
F_{\mathrm{train}}(x) = \frac{\text{Anzahl~der~x$_i$-Werte} \leq x}{n}
\label{eq:CDF_train}
\eeq
und f\"ur den Testdatensatz entsprechend.\\
Gesucht wird die gr\"o\ss te Differenz zwischen diesen beiden Verteilungen
\beq
t = \sqrt{n}\cdot\max\left|F_{\mathrm{train}}(x)-F_{\mathrm{test}}(x)\right|.
\label{eq:KSTest}
\eeq
Je kleiner dieser Wert ist, desto besser stimmen die Verteilungsfunktionen \"uberein \cite{Blobel}. Wenn dieser Wert f\"ur Test- und Trainingsdaten gro\ss~wird, so ist dies ein Hinweis darauf, dass ein Generalisierungsfehler vorliegt.

Oft wird auch die Wahrscheinlichkeit berechnet, einen Wert $\leq t_0$ f\"ur die Testgr\"o\ss e $t$ zu erhalten. In diesem Fall sind die Verteilungen bei kleinen Wahrscheinlichkeiten nicht kompatibel. Diese Wahrscheinlichkeit wird zum Beispiel von der in ROOT implementierten Funktion des KS-Tests als R\"uckgabewert genutzt \cite{ROOT:TH1F}.

%% ===========================
\section{Verwendete Datens\"atze}
\label{ch:Vergleich:sec:Daten}
%% ===========================

Um die multivariaten Algorithmen zu vergleichen werden diese auf CMS-Simulationsdaten angewendet. Als Untergrunddatensatz wird ein Datensatz mit simulierten \ttb-Ereignissen, mit in Powheg \cite{Frixione:2007vw} simuliertem Matrixelement und mit Pythia \cite{Sjostrand2015159} simuliertem Partonschauer, verwendet. Die offizielle Bezeichnung des Simulationsdatensatzes lautet {\it/TT TuneCUETP8M1 13TeV-powheg-pythia8/RunIIFall15MiniAODv2-PU25nsData2015v1-76X mcRun2 asymptotic RunIIFall15DR76 v0 ext3-v1}.\\
Als Signaldatensatz wird ein simulierter \ttH-Datensatz verwendet, bei dem das Matrixelement ebenfalls mit Powheg und der Partonschauer mit Pythia simuliert wurde. Die offizielle Bezeichnung lautet \begin{it}/ttHTobb M125 13TeV powheg pythia8/RunIIFall15MiniAODv1-PU25nsData2015v1 76X mcRun2 asymptotic v12v1/MINIAODSIM\end{it}.\\
Beide Datens\"atze wurden f\"ur eine Schwerpunktsenergie von \num{13} \si{\tera\electronvolt} simuliert. Danach wurden die Prozesse auf ihre Standardmodell-Wirkungsquerschnitte umgewichtet.

Wie in Abschnitt \ref{ch:Experiment:sec:ttH} beschrieben, unterteilt man die \ttH-Analyse in verschiedene Kategorien. Der Vergleich der multivariaten Algorithmen wird f\"ur zwei dieser Kategorien durchgef\"uhrt. F\"ur die erste Auswahl wird genau ein Lepton mit einem Transversalimpuls von $p_T\geq \num{30}~\si{\giga\electronvolt}$ und mindestens sechs Jets mit $p_T\geq \num{30}~\si{\giga\electronvolt}$, von denen vier oder mehr als b-Quark identifiziert wurden, gefordert (6 Jets und 4 B-Tags). Alle Ereignisse mit gerader Ereignisidentifikationsnummer werden zum Trainieren der BDTs verwendet, die mit ungerader zum Testen der Klassifikation. Dadurch erh\"alt man einen \ttH-Trainingsdatensatz mit 17026 Ereignissen und einen \ttb-Trainingsdatensatz mit 42378 Ereignissen.

F\"ur die zweite Auswahl wird ebenfalls genau ein Lepton mit $p_T\geq \num{30} \si{\giga\electronvolt}$ und mindestens sechs Jets mit $p_T\geq \num{30}~\si{\giga\electronvolt}$ gefordert, allerdings sollen nur zwei der Jets zu b-Quarks geh\"oren (6 Jets und 2 B-Tags). Trainings- und Testdatens\"atze werden wieder anhand gerader und ungerader Ereignisse unterschieden. Dadurch erh\"alt man insgesamt 1901054 Untergrundereignisse und 38074 Signalereignisse als Trainingsdaten, damit ist das Signal zu Untergrundverh\"altnis viel kleiner als in der Kategorie mit 6 Jets unf 4 B-Tags. Allerdings wurden nur 2364 Signalereignisse und 119823 Untergrundereignisse verwendet, um das Verhalten der Algorithmen bei geringer Statistik zu untersuchen. 

Als trennende Variablen werden in der Kategorie mit 6 Jets und 4 B-Tags\\
{\it Evt\_Deta\_JetsAverage, avg\_btag\_disc\_btags, avg\_dr\_tagged\_jets, dEta\_fn, h3, maxeta\_jet\_tag, pt\_all\_jets\_over\_E\_all\_jets, sphericity, BDT\_common5\_output, Evt\_CSV\_Average\_Tagged} und {\it Evt\_Deta\_TaggedJetsAverage}\\verwendet.

In der Kategorie mit 6 Jets und 2 B-Tags werden \\ {\it h1, avg\_dr\_tagged\_jets, sphericity, third\_highest\_btag, h3, HT, Mlb, fifth\_highest\_CSV} und {\it fourth\_highest\_btag} als trennende Variablen verwendet.\\
%{\it Evt\_Deta\_JetsAverage,avg\_btag\_disc\_btags,avg\_dr\_tagged\_jets, dEta\_fn, h3, maxeta\_jet\_tag, pt\_all\_jets\_over\_E\_all\_jets, \\sphericity, \\BDT\_common5\_output, Evt\_CSV\_Average\_Tagged und Evt\_Deta\_TaggedJetsAverage}\\verwendet.st\_btag}\\als trennende Variablen verwendet.
Alle diese Variablen haben eine physikalische Bedeutung, auf diese wird hier allerdings nicht n\"aher eingegangen, da sie f\"ur den Vergleich der multivariaten Algorithmen nicht relevant sind. Details k\"onnen in \cite{CMS-PAS-HIG-16-004} nachgeschlagen werden.

%% ===========================
\section{Vorgehensweise w\"ahrend der Untersuchung}
\label{ch:Vergleich:sec:Vorgehensweise}
%% ===========================

Wie in Tabelle \ref{tab:parameter} gezeigt, gibt es f\"ur den TMVA-Parameter nCuts keine Entsprechung in Scikit-Learn und XGBoost. Daher soll zun\"achst untersucht werden welchen Einfluss dieser Parameter hat. Dazu wird der TMVA-Algorithmus mehrfach auf den ersten Datensatz angewendet und nur der Parameter nCuts variiert. Die \"ubrigen Parameter sind jeweils NTrees=1000, MinNodeSize=2.5\%, Shrinkage=0.01, BaggedSampleFraction=0.6 und MaxDepth=2.
In Tabelle \ref{tab:nCuts} sind die Ergebnisse dieser Trainings dargestellt.

\begin{table}[tbp]\parbox{12cm}{
  \caption[Variation des TMVA-nCuts-Parameters]{Tabelle mit ROC-Integral und Wahrscheinlichkeit des Kolmogorov-Smirnov-Test f\"ur Signal- und Untergrundverteilung von TMVA-Trainings mit den festen Einstellungen NTrees=1000, MinNodeSize=2.5\%, Shrinkage=0.01, BaggedSampleFraction=0.6, MaxDepth=2 und in Abh\"angigkeit des Parameters nCuts}% {\rm \cite{Agashe:2014kda}}
  }\label{tab:nCuts}
  \begin{center}
  \begin{tabular}{llll}
  \hline
  nCuts & ROC-Integral & P(KS) Signal & P(KS) Untergrund\\
  \hline
  \num{2} & \num{0,730} & \num{0,34} & \num{0,99}\\
 \num{20} & \num{0,734} & \num{0,19} & \num{1}\\
 \num{50} & \num{0,734} & \num{0,14} & \num{1}\\
\num{500} & \num{0,734} & \num{0,27} & \num{1}\\
  \hline
  \end{tabular}
  \end{center}
\end{table}

Solange nCuts ausreichend gro\ss~gew\"ahlt wird, hat dieser Parameter bei diesem Datensatz also nur einen geringen Einfluss auf die Klassifikation. Im Folgenden wird daher immer nCuts=\num{50} verwendet.

Als n\"achstes wird versucht die anderen Parameter sinnvoll einzugrenzen. Da die BaggedSampleFraction beziehungsweise das subsample nur zur Stabilisierung des Klassifikators gedacht ist, wird diese auf den Standardwert aus TMVA, BaggedSampleFraction=\num{0,6}, gesetzt.\\
Wie in \cite{SWB-307748006} beschrieben, haben bisherige Erfahrungen gezeigt, dass BDTs die besten Resultate liefern, wenn die Anzahl an Knoten der einzelnen B\"aume zwischen vier und acht liegt, eine Lernrate unter \num{0,1} verwendet wird und die Anzahl der Entscheidungsb\"aume so gro\ss~wie m\"oglich gew\"ahlt wird, ohne in einen Bereich der \"Uberanpassung zu gelangen.\\
Der vorgeschlagenenen Anzahl an Knoten pro Baum entspricht eine Tiefe von zwei, daher wird die Tiefe ebenfalls auf zwei festgesetzt.

Die Lernrate und die Anzahl von Entscheidungsb\"aumen beeinflussen sich gegenseitig. So kann man beispielsweise nicht beiden Parametern einen hohen Wert zuweisen, ohne einen hohen Generalisierungsfehler in Kauf zu nehmen. W\"ahlt man jedoch eine kleine Lernrate, so kann man die Anzahl an Entscheidungsb\"aumen h\"oher w\"ahlen und den Generalisierungsfehler trotzdem gering halten. W\"ahrend einiger Tests stellte sich heraus, dass die besten Ergebnisse mit einer Lernrate unter \num{0,01} zustande kommen.

Obwohl diese beiden Parameter in den drei Implementierungen der Algorithmen gleich definiert sind, kann es durch die Unterschiede der Algorithmen auch unterschiedliche Ergebnisse bei gleicher Parameterwahl geben. Aus diesen Gr\"unden werden die Algorithmen nicht anhand eines einzelnen Trainings mit gleichen Parametern verglichen, sondern die Lernrate und die Anzahl B\"aume wird in einem sinnvollen Bereich variiert. Anschlie\ss end werden die besten Ergebnisse der drei Klassifikatoren miteinander verglichen.

\begin{table}[tbp]\parbox{12cm}{
  \caption[TMVA 6j4t Ergebnisse]{Tabelle mit Ergebnissen des TMVA-Algorithmus f\"ur verschiedene Parametereinstellungen in der 6 Jets 4 B-Tags Kategorie.\\In den ersten beiden Spalten sind die verwendete Anzahl der B\"aume und die verwendete Lernrate, in den weiteren Spalten ROC-Integral und die Wahrscheinlichkeiten des Kolmogorov-Smirnov-Tests f\"ur Signal- und Untergrundverteilung eingetragen.}% {\rm \cite{Agashe:2014kda}}
  }\label{tab:tmva_6j4t}
  \begin{center}
  \begin{tabular}{lllll}
  \hline
  NTrees & Shrinkage & ROC-Integral & P(KS) Signal & P(KS) Untergrund\\
  \hline
 \num{1500}  & \num{0,001}   & \num{0,729} & \num{0,2}  & \num{0,34}\\
 \num{1500}  & \num{0,0028}  & \num{0,732} & \num{0,28} & \num{0,97}\\
 \num{1500}  & \num{0,0046}  & \num{0,733} & \num{0,21} & \num{0,99}\\
 \num{1500}  & \num{0,0064}  & \num{0,734} & \num{0,22} & \num{0,99}\\
 \num{1500}  & \num{0,0082}  & \num{0,734} & \num{0,11} & \num{1}\\
 \num{1700}  & \num{0,001}   & \num{0,729} & \num{0,22} & \num{0,86}\\
 \num{1700}  & \num{0,0028}  & \num{0,732} & \num{0,23} & \num{0,99}\\
 \num{1700}  & \num{0,0046}  & \num{0,733} & \num{0,19} & \num{0,99}\\
 \num{1700}  & \num{0,0064}  & \num{0,734} & \num{0,17} & \num{0,99}\\
 \num{1700}  & \num{0,0082}  & \num{0,734} & \num{0,17} & \num{0,98}\\
 \num{1900}  & \num{0,001}   & \num{0,73}  & \num{0,26} & \num{0,78}\\
 \num{1900}  & \num{0,0028}  & \num{0,732} & \num{0,26} & \num{0,99}\\
 \num{1900}  & \num{0,0046}  & \num{0,733} & \num{0,2}  & \num{0,98}\\
 \num{1900}  & \num{0,0064}  & \num{0,734} & \num{0,16} & \num{1}\\
 \num{1900}  & \num{0,0082}  & \num{0,734} & \num{0,23} & \num{0,98}\\
 \num{2100}  & \num{0,001}   & \num{0,73}  & \num{0,23} & \num{0,72}\\
 \num{2100}  & \num{0,0028}  & \num{0,732} & \num{0,23} & \num{0,99}\\
 \num{2100}  & \num{0,0046}  & \num{0,734} & \num{0,17} & \num{0,98}\\
 \num{2100}  & \num{0,0064}  & \num{0,734} & \num{0,18} & \num{0,99}\\
 \num{2100}  & \num{0,0082}  & \num{0,735} & \num{0,29} & \num{0,94}\\
 \num{2300}  & \num{0,001}   & \num{0,730} & \num{0,26} & \num{0,9}\\
 \num{2300}  & \num{0,0028}  & \num{0,733} & \num{0,21} & \num{0,98}\\
 \num{2300}  & \num{0,0046}  & \num{0,734} & \num{0,15} & \num{1}\\
 \num{2300}  & \num{0,0064}  & \num{0,734} & \num{0,2}  & \num{1}\\
 \num{2300}  & \num{0,0082}  & \num{0,735} & \num{0,20} & \num{0,97}\\
  \hline
  \end{tabular}
  \end{center}
\end{table}

In Tabelle \ref{tab:tmva_6j4t} sind die Resultate der mit TMVA in der Kategorie mit 6 Jets und 4 B-Tags durchgef\"uhrten Trainings dargestellt. Die Tabellen mit den Resultaten der anderen Algorithmen und denjenigen mit den Untersuchungen in der Kategorie mit 6 Jets und 2 B-Tags finden sich im Anhang.

Man erkennt, dass das ROC-Integral f\"ur gro\ss e Lernraten und eine hohe Anzahl von Entscheidungsb\"aumen zunimmt, allerdings nur geringf\"ugig. Die besten Ergebnisse liefern die BDTs mit einer Lernrate von \num{0,0082} und 2100 beziehungsweise 2300 B\"aumen. Die Wahrscheinlichkeiten der Kolmogorov-Smirnov-Tests befinden sich f\"ur die Signalverteilungen im Bereich von \num{0,11} bis \num{0,29}. Aus Erfahrungen hat sich gezeigt, dass diese Werte nicht auf einen gravierenden Generalisierungsfehler hindeuten. Dies w\"are der Fall wenn die Wahrscheinlichkeit gegen Null geht. Daher wird jeweils ein Wert gr\"o\ss er \num{0,1} gefordert.

Wie bei den Trainings mit TMVA wird die Fl\"ache unter der ROC-Kurve gr\"o\ss er, je h\"oher die Lernrate und die Anzahl der Entscheidungsb\"aume sind. Allerdings werden die Wahrscheinlichkeiten des Kolmogorov-Smirnov-Tests deutlich kleiner als bei den TMVA-Trainings. So fallen relativ viele unterhalb der bei \num{0,1} gesetzten Marke und werden nicht ber\"ucksichtigt. Aufgrund dessen ist die beste Einstellung, die f\"ur Scikit-Learn gefunden wurde, eine Lernrate von \num{0,0046} und \num{2300} Entscheidungsb\"aumen.

Auch XGBoost erreicht die besten Ergebnisse mit gr\"o\ss eren Lernraten und vielen Entscheidungsb\"aumen. Hier liegen die Wahrscheinlichkeiten aus dem Kolmogorov-Smirnov-Tests weiter auseinander als bei den anderen beiden Algorithmen. Es gibt auch Trainings, die aufgrund des schlechten Ergebnisses beim Kolmogorov-Smirnov-Test nicht ber\"ucksichtigt werden, mit drei sind dies aber deutlich weniger als bei Scikit-Learn. Das beste Ergebnis wird mit einer Lernrate von \num{0,0064} und \num{2300} Entscheidungsb\"aumen erreicht.

\begin{figure}[tbp]
\centering     %%% not \center
\subfigure[ROC-Kurven der jeweils besten Trainings]{\label{fig:ROC_6j4t}\includegraphics[width=0.49\textwidth]{graphics/ROC_6j4t.pdf}}
\subfigure[RBDT-Ausgabe der jeweils besten Trainings]{\label{fig:BDTout_6j4t}\includegraphics[width=0.49\textwidth]{graphics/BDToutput_6j4t.pdf}}
\caption{Links sind die ROC-Kurven der jeweils besten Trainings in der Kategorie mit mindestens sechs Jets und mindestens vier B-Tags abgebildet, rechts jeweils die BDT-Ausgaben.}
\end{figure}

In Abbildung \ref{fig:ROC_6j4t} sind die ROC-Kurven der jeweils besten Trainings abgebildet. Sie sind nahezu identisch. In Abbildung \ref{fig:BDTout_6j4t} sind die BDT-Ausgaben der besten Training zu sehen. Man sieht, dass f\"ur jeden Klassifikator die BDT-Ausgabe etwas anders definiert ist. XGBoost gibt beispielsweise die Signalwahrscheinlichkeit f\"ur ein Ereignis zur\"uck, w\"ahrend TMVA einen Wert zwischen $\pm1$ zur\"uckgibt.

Generell sind die ROC-Integrale in der Kategorie mit 6 Jets und 4 B-Tags kleiner als in der Kategorie mit 6 Jets und 4 B-Tags. Dies liegt vor allem daran, dass die Kategorie stark untergrunddominiert ist, also nur wenige Signalereignisse auf viele Untergrundereignisse fallen.

Die Fl\"ache unter der ROC-Kurve ist in dieser Kategorie mit Scikit-Learn immer etwa \num{0,01} gr\"o\ss er als bei TMVA. Allerdings f\"allt der Kolmogorov-Smirnov-Test sehr schlecht aus, allerdings kann dies \"uber andere Einstellungen, beispielsweise bei min\_samples\_leaf, noch verbessert werden.

XGBoost schneidet in dieser Kategorie ebenfalls besser ab als TMVA und der Kolmogorov-Smirnov-Test f\"allt etwas besser aus als bei Scikit-Learn.

\begin{figure}[tbp]
\centering     %%% not \center
\subfigure[ROC-Kurven der jeweils besten Trainings]{\label{fig:ROC_6j4t}\includegraphics[width=0.49\textwidth]{graphics/ROC_6j2t.pdf}}
\subfigure[BDT-Ausgabe der jeweils besten Trainings]{\label{fig:BDTout_6j4t}\includegraphics[width=0.49\textwidth]{graphics/BDToutput_6j2t.pdf}}
\caption{Links sind die ROC-Kurven der jeweils besten Trainings in der Kategorie mit mindestens sechs Jets und zwei B-Tags abgebildet, rechts jeweils die normierten BDT-Ausgaben.}
\end{figure}

In Abbildung \ref{fig:ROC_6j4t} sind die ROC-Kurven der jeweils besten Trainings gezeigt. In der Kategorie mit mindestens sechs Jets und zwei B-Tags ist ein Unterschied zwischen den ROC-Kurven zu erkennen. In Abbildung \ref{fig:BDTout_6j4t} sind die BDT-Ausgaben abgebildet. Aufgrund des geringen Signal-zu-Untergrund-Verh\"altnisses wurden die Verteilungen normiert.

Urspr\"unglich sollte auch die zum Trainieren der BDTs ben\"otigte Zeit verglichen werden. Allerdings wurden alle Trainings auf einem Rechencluster durchgef\"uhrt. Je nach Auslastung des Clusters varierten die Trainingszeiten, daher ist kein objektiver Vergleich m\"oglich. Generell nimmt die Zeit, die man f\"ur ein Training ben\"otigt, mit der Zahl der Entscheidungsb\"aume zu, weswegen eine Abw\"agung von Klassifikationseffizienz zur Trainingsdauer n\"otig ist.

%% ===========================
\section{Nutzbarkeit der Algorithmen in der \ttH-Analyse}
\label{ch:Vergleich:sec:ttH}
%% ===========================

In diesem Abschnitt soll gekl\"art werden, inwieweit sich die getesteten Algorithmen in der \ttH-Analyse einsetzen lassen.

Eine der wichtigsten Anforderungen an die multivariaten Algorithmen in der \ttH-Analyse ist die M\"oglichkeit den Klassifikator zu speichern, sodass die im Detektor gemessenen Daten mit einem zuvor auf Simulationsdaten trainierten Klassifikator analysiert werden k\"onnen.

Bei dem zur Zeit verwendeten TMVA BDT werden die Schnitte und Gewichte des Trainings in eine Textdatei (.xml-Format) gespeichert. Diese kann mithilfe einer eigenen Klasse, dem TMVA-Reader geladen werden. Durch die geladenen BDT-Gewichte, kann der TMVA-Reader dann eine Vorhersage f\"ur unbekannte Daten \"ubernehmen.

In Scikit-Learn besteht die M\"oglichkeit den Klassifikator direkt mit dem Python-Paket \glqq pickle\grqq~ als Packing-List-File (.pkl-Datei) zu Speichern und wieder zu laden. Der Klassifikator stellt hier selbst Funktionen bereit, mit denen Vorhersagen auf unbekannte Daten erstellt werden k\"onnen, ohne dass eine separates Objekt erstellt werden muss.

Bei der mit dem Transformationsskript aufgerufenen Implementation von XGBoost besteht die gleiche M\"oglichkeit, den Klassifikator zu speichern. Allerdings war dies w\"ahrend der Tests aufgrund von Kompatibilit\"atsproblemen nicht m\"oglich.

Dies f\"uhrt zu einem weiteren wichtigen Punkt, der beachtet werden muss. In der CMS-Kollaboration wird das CMSSW Application Framework \cite{CMSSW} genutzt. Dies kann man sich als eine Art virtuelles System vorstellen, auf dem in einem modularen Aufbau Software bereitgestellt wird. W\"ahrend ROOT inklusive TMVA in CMSSW integriert sind, wird zur Zeit weder Scikit-Learn noch XGBoost bereitgestellt. F\"ur die Untersuchungen im Rahmen dieser Arbeit wurde teils auf Softwaremodule des CMSSW-Framework zur\"uckgegriffen, die mit lokalen Installationen von Scikit-Learn und XGBoost erg\"anzt wurden. Allerdings war die Installation und Konfiguration kompliziert.

Dies stellt derzeit einen klaren Nachteil f\"ur Scikit-Learn und XGBoost dar. Solange diese Pakete nicht ins CMSSW-Framework integriert werden, ist eine Nutzung in der \ttH-Analyse nicht sinnvoll.