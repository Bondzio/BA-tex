%% zusammenfassung.tex
%%

%% ==================
\chapter{Fazit und Ausblick}
\label{ch:Fazit}
%% ==================

{\bibliographystyle{babunsrt-fl}}

In diesem Kapitel sollen nochmals alle Resultate zusammengefasst und ein Fazit gezogen werden. Anschlie\ss end wird ein kurzer Ausblick gegeben.

Insgesamt sind in der Kategorie mit mindestens sechs Jets und mindestens vier B-Tags keine signifikanten Unterschiede in den ROC-Kurven und somit in der G\"ute der getesteten Algorithmen zu erkennen. In der Kategorie mit mindestens sechs Jets und zwei B-Tags, die sehr viele Untergrundereignisse und nur wenig Signalereignisse aufweist, ist der TMVA-Algorithmus etwas schlechter als der in Scikit-Learn implementierte und XGBoost. Die Unterschiede sind allerdings nicht signifikant genug, als dass ein Wechsel zu einem der anderen Algorithmen unbedingt n\"otig w\"are.

W\"ahrend der Untersuchungen mit den verschiedenen BDTs stellte sich heraus, dass die besten Ergebnisse, unabh\"angig vom verwendeten Algorithmus, bei einer gro\ss en Anzahl Entscheidungsb\"aumen (etwa 2000) und kleiner Lernrate ($\leq \num{0,01}$) erzielt werden. Und auch wenn sich zwischen einzelnen Algorithmen kaum signifikante Unterschiede ergeben, lohnt es sich, geeignete Parameter zu suchen. Mit gut gew\"ahlten Parametern l\"asst sich die Klassifikation jedes Algorithmus verbessern. Allerdings wird es immer M\"oglichkeiten geben die Einstellungen so zu ver\"andern, dass sich die Klassifikation etwas verbessert. Es gilt abzuw\"agen inwieweit eine marginale Verbesserung die deutlich l\"angeren Trainingszeiten rechtfertigt.\\
Ein weiteres Mittel die Klassifikation der BDTs zu verbessern, ist die Wahl geeigneter Eingangsvariablen, auf die in dieser Arbeit nicht eingegangen wurde. Somit kann auch ohne gro\ss e Unterschiede zwischen verschiedenen Algorithmen eine Optimierung der Einstellungen einzelner BDT-Implementierungen wertvoll f\"ur die \ttH-Analyse sein.

Auf jeden Fall sollte weiterhin getestet werden, ob es Klassifikatoren gibt, die bessere Ergebnisse erzielen. Es w\"are beispielsweise auch interessant komplett andere Klassifikatoren wie Random Forests oder Neuronale Netze zu testen.

Der n\"achste Schritt sollte sein, weitere multivariate Algorithmen neben TMVA in das CMSSW-Framework zu integrieren, um weitere Tests zu vereinfachen.